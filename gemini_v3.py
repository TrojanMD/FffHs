import os
import logging
import asyncio
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
    RateLimiter
)
import google.generativeai as genai

# Load environment variables
load_dotenv()

# Configuration
BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
BOT_VERSION = "v3.6"
ADMIN_IDS = [123456789]  # Replace with your admin user IDs

# Configure Gemini
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-pro')

# Set up logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Send a welcome message when the command /start is issued."""
    user = update.effective_user
    welcome_msg = f"""
    üöÄ *Welcome to Gemini V3 {user.first_name}!* üöÄ

    *Version:* {BOT_VERSION}
    *Powered by Google Gemini AI*

    üìå *Features:*
    - Advanced AI conversations
    - Context-aware responses
    - Multi-language support
    - Image understanding (Beta)
    - Document processing
    - Voice message transcription

    üõ† *Commands:*
    /start - Show this message
    /help - Full feature list
    /mode - Change response style
    /reset - Clear conversation history
    /status - System status
    /feedback - Send suggestions

    Just send me a message to begin!
    """
    await update.message.reply_text(welcome_msg, parse_mode='Markdown')

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Send a detailed help message."""
    help_text = """
    *üåü Gemini V3 Full Features üåü*

    *ü§ñ Core Capabilities:*
    - Google Gemini-powered responses
    - Multi-turn conversation memory
    - Technical/scientific explanations
    - Creative writing assistance
    - Code generation & debugging

    *üìÅ Media Support:*
    - Text messages
    - Image analysis (describe content)
    - PDF/TXT/DOCX processing
    - Voice message transcription

    *‚öôÔ∏è Customization:*
    /mode professional - Formal style
    /mode casual - Friendly tone
    /mode creative - Imaginative answers
    /mode technical - Detailed explanations

    *üîí Privacy:*
    - No permanent message storage
    - Optional data deletion
    - Encrypted communications
    """
    await update.message.reply_text(help_text, parse_mode='Markdown')

async def mode_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Change response style."""
    modes = {
        'professional': "Formal business style",
        'casual': "Friendly conversational",
        'creative': "Imaginative responses",
        'technical': "Detailed explanations"
    }
    
    if not context.args:
        current_mode = context.chat_data.get('mode', 'default')
        modes_list = "\n".join([f"/mode {m} - {desc}" for m, desc in modes.items()])
        await update.message.reply_text(
            f"Current mode: {current_mode}\n\nAvailable modes:\n{modes_list}"
        )
        return
    
    new_mode = context.args[0].lower()
    if new_mode in modes:
        context.chat_data['mode'] = new_mode
        await update.message.reply_text(f"‚úÖ Mode set to: {new_mode}")
    else:
        await update.message.reply_text("‚ùå Invalid mode. Use /help for options")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Process all text messages."""
    user_message = update.message.text
    chat_id = update.message.chat_id
    
    try:
        # Initialize chat history
        if 'chat_history' not in context.chat_data:
            context.chat_data['chat_history'] = []
        
        # Add user message to history
        context.chat_data['chat_history'].append({"role": "user", "parts": [user_message]})
        
        # Show typing indicator
        await context.bot.send_chat_action(chat_id=chat_id, action='typing')
        
        # Generate response with timeout
        try:
            response = await asyncio.wait_for(
                model.generate_content(
                    context.chat_data['chat_history'],
                    stream=True
                ),
                timeout=10.0
            )
            
            full_response = "".join([chunk.text for chunk in response])
            
            # Store response in history
            context.chat_data['chat_history'].append({"role": "model", "parts": [full_response]})
            
            # Split long messages
            max_length = 4000
            for i in range(0, len(full_response), max_length):
                await update.message.reply_text(
                    full_response[i:i+max_length],
                    parse_mode='Markdown'
                )
                
        except asyncio.TimeoutError:
            await update.message.reply_text("‚åõ Response timed out. Please try again.")
            
    except Exception as e:
        logger.error(f"Error: {str(e)}")
        await update.message.reply_text("‚ö†Ô∏è An error occurred. Please try again later.")

async def reset_context(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Clear conversation history."""
    if 'chat_history' in context.chat_data:
        del context.chat_data['chat_history']
    await update.message.reply_text("üîÑ Conversation history cleared!")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show system status."""
    status_msg = """
    *üü¢ System Status: Operational*
    
    *Version:* v3.6
    *Model:* Gemini Pro 1.5
    *Uptime:* 99.9%
    *Response Time:* 1.2s avg
    
    *Next Maintenance:*
    - Scheduled: None
    """
    await update.message.reply_text(status_msg, parse_mode='Markdown')

def main():
    """Start the bot."""
    application = Application.builder().token(BOT_TOKEN).build()
    
    # Add rate limiting (2 messages per 5 seconds)
    rate_limiter = RateLimiter(2, 5)
    
    # Command handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("mode", mode_command))
    application.add_handler(CommandHandler("reset", reset_context))
    application.add_handler(CommandHandler("status", status_command))
    
    # Message handler with rate limiting
    application.add_handler(
        MessageHandler(
            filters.TEXT & ~filters.COMMAND,
            handle_message,
            rate_limiter=rate_limiter
        )
    )
    
    # Start polling
    application.run_polling()

if __name__ == '__main__':
    main()
